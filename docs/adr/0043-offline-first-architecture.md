# ADR 043: Offline-First Architecture using RxDB and Connect-go

## Status

- **Status**: Accepted
- **Date**: 2026-02-11
- **Authors**: @jalbarran
- **Technical Domain**: Backend / Frontend

## Context

**Dilocash** requires high resilience. Users must be able to record financial transactions in zero or low-connectivity environments (e.g., subways, rural areas). Furthermore, the architecture must support an **Open Core** model where basic synchronization is Open Source (OSS), while advanced features—such as AI-driven conflict resolution or field-level encryption—are reserved for the Premium repository.

We need a solution that:

1. Operates identically across Web (PWA) and Mobile (Android/iOS via Expo).
2. Guarantees data and type integrity between the Go Backend and the TypeScript Frontend.
3. Minimizes battery and data consumption via binary protocols.

## Decision

We will implement a data pipeline based on **RxDB** as the local database and **Connect-go** as the gRPC communication bridge.

### 1. Polyglot Persistence (Storage Layer)

We will utilize the RxDB adapter pattern to abstract physical storage based on the platform:

* **Web (Next.js):** `storage-dexie` (IndexedDB).
* **Native (Android/Expo):** `storage-sqlite` (via `expo-sqlite`).

### 2. Data Contract (Single Source of Truth)

The local database schema will be strictly derived from **Protocol Buffer (.proto)** definitions.

* TypeScript types generated by Connect-go will serve as the base for RxDB interfaces.
* Any change to the `Transaction` entity in the Go backend will trigger a type mismatch in the frontend, forcing a schema update.

### 3. Replication Mechanism

We will implement a custom **Replication Plugin** in RxDB that consumes Connect-go services.

* **Push:** Local changes will be sent in batches to the gRPC endpoint.
* **Pull:** The client will query for updates based on a `checkpoint` (last synchronization timestamp).
* **Frequency:** "Live" synchronization when online, with exponential backoff retries during network outages.

### 4. Service Worker Integration (PWA)

For the Web version (Next.js), we will use **Serwist** to:

* Pre-cache UI assets (Gluestack components).
* Register **Background Sync** tasks that trigger RxDB replication even if the browser tab is closed.

## Consequences

### Positive

* **Zero Latency:** Gluestack UI updates instantly as it always reads from the local database.
* **Type Safety:** Eliminates "missing field" errors between frontend and backend due to Protobuf's strict nature.
* **Reduced Server Overhead:** Delta-based synchronization (checkpoints) significantly reduces CPU load on the Fargate clusters.

### Negative / Risks

* **Bundle Size:** RxDB and its dependencies (Dexie/SQLite) add an initial JS overhead (~50-100kb). This will be mitigated via Code Splitting in Next.js.
* **Migration Complexity:** Managing schema changes across thousands of distributed local databases requires a robust versioning strategy within RxDB.

## Technical Implementation Blueprint

| Component | Technology | Monorepo Location |
| --- | --- | --- |
| **Schemas** | RxJsonSchema + Protos | `packages/db/schemas` |
| **Transport** | Connect-go (HTTP/2) | `packages/api-client` |
| **UI State** | RxDB Observables | `apps/web` & `apps/expo` |
| **PWA Logic** | Serwist + Workbox | `apps/web/sw.ts` |

---

### Synchronization Workflow

1. **User Input:** Gluestack Form -> RxDB (Local Insert).
2. **Reactivity:** RxDB Observable -> UI Update (Shows "Pending" icon).
3. **Sync Trigger:** Replicator -> Connect-go Client -> AWS Fargate (Go).
4. **Acknowledgment:** Fargate -> Postgres (Commit) -> gRPC Response.
5. **Finality:** RxDB (Update status to 'synced') -> UI Update (Shows "Check" icon).

---